{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoAuyt1xlKXN",
        "outputId": "c52e64aa-7d72-43c2-9893-54af886db119"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "Spot = 36   # stock price\n",
        "σ = 0.2     # stock volatility\n",
        "K = 40      # strike price\n",
        "r = 0.06    # risk free rate\n",
        "n = 20000  # Number of simualted paths\n",
        "m = 50      # number of exercise dates\n",
        "T = 1       # maturity\n",
        "order = 6   # Polynmial order\n",
        "Δt = T / m  # interval between two exercise dates\n",
        "\n",
        "\n",
        "def create_polynomials():\n",
        "    model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
        "    #model = tf.keras.Sequential([tf.keras.layers.Dense(1,input_dim=2)])\n",
        "    return model\n",
        "\n",
        "\n",
        "networks = {t: create_polynomials() for t in range(1, m)}\n",
        "\n",
        "\n",
        "# simulates the stock price evolution\n",
        "def advance(S, r, σ, Δt, n):\n",
        "    dB = tf.sqrt(Δt) * tf.random.normal(shape=tf.shape(S))\n",
        "    out = S + r * S * Δt + σ * S * dB\n",
        "    return out\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "#optimizer = tf.keras.optimizers.RMSprop(0.01)\n",
        "#optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "\n",
        "\n",
        "# LSMC algorithm\n",
        "#@tf.function\n",
        "def train_step(order, Spot, σ, K, r):\n",
        "    tf.random.set_seed(0)\n",
        "    S0 = Spot * tf.ones((n,1))\n",
        "    S = {0: S0}\n",
        "\n",
        "    for t in range(m):\n",
        "        S[t + 1] = advance(S[t], r, σ, Δt, n)\n",
        "\n",
        "    discount = tf.exp(-r * Δt)\n",
        "    CFL = {t: tf.maximum(0., K - S[t]) for t in range(m + 1)}\n",
        "    value_tp1 = CFL[m] * discount\n",
        "    CV = {m: tf.zeros_like(S[0])}\n",
        "\n",
        "    for t in range(m - 1, 0, -1):\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            features = S[t]\n",
        "            target = value_tp1\n",
        "            CV[t] = networks[t](features) # the continuation value predicted by the network\n",
        "            mse_loss = 0.5 * tf.reduce_mean((CV[t] - target)**2)\n",
        "            #mse_loss = tf.reduce_sum(tf.keras.losses.mean_squared_error(target,CV[t]))\n",
        "        Θ = networks[t].weights\n",
        "        grads = tape.gradient(mse_loss, Θ)\n",
        "        optimizer.apply_gradients(zip(grads, Θ))\n",
        "\n",
        "        CV[t] = networks[t](features)\n",
        "        exercise = tf.math.greater(CFL[t],CV[t])\n",
        "        value_t = tf.where(exercise, CFL[t], value_tp1)\n",
        "        #value_t = tf.where(CFL[t] > CV[t], CFL[t], value_tp1)\n",
        "        value_tp1 = discount * value_t\n",
        "    \n",
        "    POF = {t: tf.where(CV[t] < CFL[t], CFL[t], 0) for t in range(1, m + 1)}\n",
        "    POF[m] = tf.constant(POF[m],shape=(n,1))\n",
        "    POF[m-1] = tf.constant(POF[m-1],shape=(n,1))\n",
        "    #print(POF.values())  \n",
        "\n",
        "    POF = tf.stack(list(POF.values()),axis=0)\n",
        "\n",
        "    POF = tf.constant(POF, shape=(m,n))\n",
        "    idx_payoffs = tf.math.argmax(POF > 0, axis=0)\n",
        "    FPOF = tf.transpose(tf.one_hot(idx_payoffs, m)) * POF\n",
        "    m_range = tf.constant(range(0, m), shape=(m,1),dtype=tf.float32)\n",
        "    dFPOF = FPOF * tf.math.exp(-r * m_range * Δt)\n",
        "    dFPOF=tf.reduce_sum(dFPOF)\n",
        "    PRICE = dFPOF / n\n",
        "    return(PRICE)\n",
        "\n",
        "    #PRICE = tf.reduce_sum(CV[1])/n\n",
        "\n",
        "    return PRICE\n",
        "\n",
        "#print(train_step(order, Spot, σ, K, r))\n",
        "\n",
        "#for iteration in range(1000000):\n",
        "for iteration in range(1000):\n",
        "    PRICE = train_step(order, Spot, σ, K, r)\n",
        "    if iteration % 100 == 0:\n",
        "        print(PRICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(3.964233, shape=(), dtype=float32)\n",
            "tf.Tensor(4.27945, shape=(), dtype=float32)\n",
            "tf.Tensor(4.2792115, shape=(), dtype=float32)\n",
            "tf.Tensor(4.279047, shape=(), dtype=float32)\n",
            "tf.Tensor(4.279131, shape=(), dtype=float32)\n",
            "tf.Tensor(4.279191, shape=(), dtype=float32)\n",
            "tf.Tensor(4.2793336, shape=(), dtype=float32)\n",
            "tf.Tensor(4.2795577, shape=(), dtype=float32)\n",
            "tf.Tensor(4.27978, shape=(), dtype=float32)\n",
            "tf.Tensor(4.279594, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MR0_IL_l0Re"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}